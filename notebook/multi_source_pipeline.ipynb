{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323dba65",
   "metadata": {},
   "source": [
    "# Multi Source RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd81df",
   "metadata": {},
   "source": [
    "### Document Loaders\n",
    "\n",
    "1. Pdf(Text Only)\n",
    "2. Csv\n",
    "3. Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b3c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader,SitemapLoader,WebBaseLoader,RecursiveUrlLoader,AsyncHtmlLoader\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader \n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322d6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for plain text pdfs\n",
    "def pdf_loader(pdf_dir):\n",
    "    all_docs = []\n",
    "    dir = Path(pdf_dir)\n",
    "\n",
    "    pdf_files = list(dir.glob(\"**/*.pdf\"))\n",
    "    print(\"loaded documents\")\n",
    "    for p in pdf_files:\n",
    "        loader = PyMuPDFLoader(\n",
    "            file_path=p,\n",
    "            mode=\"page\"\n",
    "        )\n",
    "\n",
    "        documents = loader.load()\n",
    "        for doc in documents:\n",
    "            doc.metadata['creationdata'] = str(datetime.datetime.now())\n",
    "            doc.metadata['source_file']=p.name\n",
    "            doc.metadata['file_type'] = 'pdf'\n",
    "            all_docs.append(doc)\n",
    "    print(\"done\")\n",
    "    return all_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233afeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#csv loader\n",
    "def csv_loader(csv_dir):\n",
    "    all_documents = []\n",
    "    dir = Path(csv_dir)\n",
    "\n",
    "    csv_files = list(dir.glob(\"**/*.csv\"))\n",
    "    for c in csv_files:\n",
    "        loader = CSVLoader(\n",
    "        file_path=c,\n",
    "        csv_args={\n",
    "            \"delimiter\":\",\",\n",
    "            }             \n",
    "        )\n",
    "\n",
    "        documents = loader.load()\n",
    "        for doc in documents:\n",
    "            doc.metadata['source_file']=c.name\n",
    "            doc.metadata['creationdata'] = str(datetime.datetime.now())\n",
    "            doc.metadata['format'] = \"csv\"\n",
    "\n",
    "            all_documents.append(doc)\n",
    "\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41930c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional,Sequence\n",
    "from langchain_classic.schema import Document\n",
    "\n",
    "\n",
    "class WebLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.html_transformer = Html2TextTransformer()\n",
    "\n",
    "    def _postprocess(self,docs:Sequence[Document],source_type:str)->List[Document]:\n",
    "        \"\"\" Post-process documents by cleaning content and adding metadata. \"\"\"\n",
    "        processed_docs = []\n",
    "        for d in docs:\n",
    "            d.page_content = d.page_content.strip()\n",
    "            d.metadata.update({\n",
    "                \"source_type\": source_type,\n",
    "                \"ingested_at\": str(datetime.datetime.now()),\n",
    "                \"content_length\": len(d.page_content)\n",
    "            })\n",
    "\n",
    "            if d.page_content:\n",
    "                processed_docs.append(d)\n",
    "        \n",
    "        return processed_docs\n",
    "\n",
    "\n",
    "    def load_single_page(self,url:str)->List[Document]:\n",
    "        \"\"\" Load a single Web Page \"\"\"\n",
    "        docs = WebBaseLoader(url).load()\n",
    "        process =self._postprocess(docs, \"web_page\")\n",
    "        return process\n",
    "\n",
    "\n",
    "    def load_sitemap(self, sitemap_url: str, filter_urls: Optional[List[str]] = None) -> List[Document]:\n",
    "        \"\"\" Load all pages from a sitemap \"\"\"\n",
    "        loader = SitemapLoader(sitemap_url, filter_urls=filter_urls)\n",
    "        docs = loader.load()\n",
    "        processed = self._postprocess(docs, \"sitemap\")\n",
    "\n",
    "        return processed\n",
    "\n",
    "    def load_recursive(self, base_url: str, max_depth: int = 2) -> List[Document]:\n",
    "        \"\"\"  Recursively crawl a website starting from a base URL. \"\"\"\n",
    "        docs = RecursiveUrlLoader(\n",
    "            url=base_url,\n",
    "            max_depth=max_depth\n",
    "        ).load()\n",
    "        processed = self._postprocess(docs, \"recursive\")\n",
    "        \n",
    "        return processed\n",
    "\n",
    "\n",
    "    def load_async_urls(self,urls: List[str])->List[Document]:\n",
    "        \"\"\" Load multiple URLs asynchronously for faster processing. \"\"\"\n",
    "        loader = AsyncHtmlLoader(urls)\n",
    "        docs = list(loader.lazy_load())\n",
    "\n",
    "        docs = self.html_transformer.transform_documents(docs)\n",
    "        processed = self._postprocess(docs, \"async\")\n",
    "\n",
    "        return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4265ac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '': No scheme supplied. Perhaps you meant https://?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMissingSchema\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m async_urls = []\n\u001b[32m      9\u001b[39m single_page = web_loader.load_single_page(single_page_url)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m sitemap_page = \u001b[43mweb_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_sitemap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msitemap_page_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m recursive_page = web_loader.load_recursive(recursive_docs_url)\n\u001b[32m     12\u001b[39m async_docs = web_loader.load_async_urls(async_urls)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mWebLoader.load_sitemap\u001b[39m\u001b[34m(self, sitemap_url, filter_urls)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Load all pages from a sitemap \"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m loader = SitemapLoader(sitemap_url, filter_urls=filter_urls)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m processed = \u001b[38;5;28mself\u001b[39m._postprocess(docs, \u001b[33m\"\u001b[39m\u001b[33msitemap\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:43\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into `Document` objects.\u001b[39;00m\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m        The documents.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\sitemap.py:216\u001b[39m, in \u001b[36mSitemapLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m     soup = bs4.BeautifulSoup(fp, \u001b[33m\"\u001b[39m\u001b[33mxml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     soup = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m els = \u001b[38;5;28mself\u001b[39m.parse_sitemap(soup)\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\langchain_community\\document_loaders\\web_base.py:357\u001b[39m, in \u001b[36mWebBaseLoader._scrape\u001b[39m\u001b[34m(self, url, parser, bs_kwargs)\u001b[39m\n\u001b[32m    353\u001b[39m         parser = \u001b[38;5;28mself\u001b[39m.default_parser\n\u001b[32m    355\u001b[39m \u001b[38;5;28mself\u001b[39m._check_parser(parser)\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m html_doc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequests_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_for_status:\n\u001b[32m    359\u001b[39m     html_doc.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\requests\\sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\requests\\sessions.py:575\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[32m    563\u001b[39m req = Request(\n\u001b[32m    564\u001b[39m     method=method.upper(),\n\u001b[32m    565\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m     hooks=hooks,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m prep = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m proxies = proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    579\u001b[39m settings = \u001b[38;5;28mself\u001b[39m.merge_environment_settings(\n\u001b[32m    580\u001b[39m     prep.url, proxies, stream, verify, cert\n\u001b[32m    581\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\requests\\sessions.py:484\u001b[39m, in \u001b[36mSession.prepare_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    481\u001b[39m     auth = get_netrc_auth(request.url)\n\u001b[32m    483\u001b[39m p = PreparedRequest()\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\requests\\models.py:367\u001b[39m, in \u001b[36mPreparedRequest.prepare\u001b[39m\u001b[34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_method(method)\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_headers(headers)\n\u001b[32m    369\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_cookies(cookies)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\svmra\\OneDrive\\Documents\\projects\\Multi-source-RAG\\.venv\\Lib\\site-packages\\requests\\models.py:438\u001b[39m, in \u001b[36mPreparedRequest.prepare_url\u001b[39m\u001b[34m(self, url, params)\u001b[39m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(*e.args)\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[32m    439\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: No scheme supplied. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    440\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    441\u001b[39m     )\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: No host supplied\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mMissingSchema\u001b[39m: Invalid URL '': No scheme supplied. Perhaps you meant https://?"
     ]
    }
   ],
   "source": [
    "all_docs = []\n",
    "web_loader = WebLoader()\n",
    "\n",
    "single_page_url = \"https://www.google.com\"\n",
    "sitemap_page_url = \"\"\n",
    "recursive_docs_url = \"\"\n",
    "async_urls = []\n",
    "\n",
    "single_page = web_loader.load_single_page(single_page_url)\n",
    "#sitemap_page = web_loader.load_sitemap(sitemap_page_url)\n",
    "#recursive_page = web_loader.load_recursive(recursive_docs_url)\n",
    "#async_docs = web_loader.load_async_urls(async_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09851fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.google.com', 'title': 'Google', 'language': 'en-IN', 'source_type': 'web_page', 'ingested_at': '2026-01-13 11:07:06.152257', 'content_length': 266}, page_content='GoogleSearch Images Maps Play YouTube News Gmail Drive More »Web History | Settings | Sign in\\xa0Advanced searchGoogle offered in:  हिन्दी বাংলা తెలుగు मराठी தமிழ் ગુજરાતી ಕನ್ನಡ മലയാളം ਪੰਜਾਬੀ AdvertisingBusiness SolutionsAbout GoogleGoogle.co.in© 2026 - Privacy - Terms')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba05e4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded documents\n",
      "done\n",
      "page_content='Government of India\n",
      "2023-24' metadata={'producer': 'Adobe PDF Library 16.0.7', 'creator': 'Adobe InDesign 17.4 (Windows)', 'creationdate': '2024-07-20T20:21:03+05:30', 'source': '..\\\\data\\\\pdf\\\\ecsurvey.pdf', 'file_path': '..\\\\data\\\\pdf\\\\ecsurvey.pdf', 'total_pages': 524, 'format': 'PDF 1.6', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-07-22T11:48:47+05:30', 'trapped': '', 'modDate': \"D:20240722114847+05'30'\", 'creationDate': \"D:20240720202103+05'30'\", 'page': 0, 'creationdata': '2026-01-20 10:52:49.232913', 'source_file': 'ecsurvey.pdf', 'file_type': 'pdf'}\n",
      "{'source': '..\\\\data\\\\csv\\\\cereal.csv', 'row': 0, 'source_file': 'cereal.csv', 'creationdata': '2026-01-20 10:52:49.256256', 'format': 'csv'}\n"
     ]
    }
   ],
   "source": [
    "p = pdf_loader(\"../data\")\n",
    "c = csv_loader(\"../data\")\n",
    "\n",
    "print(p[0])\n",
    "print(c[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d677018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic chunking\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01633ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False)\n",
    "\n",
    "chunked_document = text_splitter.split_documents(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad70762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00ec10b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model {'all-MiniLM-L6-v2'}\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class EmbeddingManager:\n",
    "\n",
    "    def __init__(self,model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "            try:\n",
    "                self.model=SentenceTransformer(self.model_name)\n",
    "                print(\"Loading model\",{self.model_name})\n",
    "                print(self.model.get_sentence_embedding_dimension())\n",
    "            except Exception as e:\n",
    "                raise ValueError(\"error in load_model\")\n",
    "    \n",
    "    def generate_embedding(self,texts:List[str]) -> np.ndarray:\n",
    "            if not self.model:\n",
    "                raise ValueError(\"model not initiated\")\n",
    "            \n",
    "            embeddings = self.model.encode(texts,show_progress_bar=True)\n",
    "            return embeddings\n",
    "        \n",
    "\n",
    "embedding_manager = EmbeddingManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a508ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store has been Initialized for Collection: {'pdf_documents'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x26d291aaba0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class VectorStore:\n",
    "\n",
    "    def __init__(self,collection_name:str=\"pdf_documents\",persist_dir:str = \"../data/vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persis_dir = persist_dir\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "    \n",
    "    def _initialize_store(self):\n",
    "        try:\n",
    "            os.makedirs(self.persis_dir,exist_ok = True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persis_dir)\n",
    "\n",
    "            self.collection=self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata={\"description\":\"PDF embeddings for RAG\"})\n",
    "            print(\"Vector store has been Initialized for Collection:\",{self.collection_name})\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"error in Vector Store initializing\",e)\n",
    "        \n",
    "    def add_documents(self,documents:List[Any],embeddings:np.ndarray):\n",
    "\n",
    "        if(len(documents)!=len(embeddings)):\n",
    "            raise ValueError(\"Error\")\n",
    "        \n",
    "        ids = []\n",
    "        metadatas=[]\n",
    "        document_text = []\n",
    "        embedding_list = []\n",
    "\n",
    "        for i,(doc,embed) in enumerate(zip(documents,embeddings)):\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "\n",
    "            metadatas.append(metadata)\n",
    "            document_text.append(doc.page_content)\n",
    "            \n",
    "            embedding_list.append(embed.tolist())\n",
    "\n",
    "        if not documents or not embedding_list:\n",
    "            raise ValueError(\"Documents or embeddings are empty\")\n",
    "\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids = ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=document_text,\n",
    "                embeddings=embedding_list\n",
    "\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "    \n",
    "vector_store = VectorStore()\n",
    "vector_store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23732f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 70/70 [01:29<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09751279 -0.01514472 -0.02372612 ... -0.05802242  0.00421078\n",
      "   0.02525925]\n",
      " [-0.05923247 -0.05849332 -0.07195604 ... -0.08649798 -0.08849315\n",
      "   0.01236684]\n",
      " [ 0.02185366 -0.02050512 -0.07425625 ... -0.07585315  0.04138426\n",
      "  -0.01694065]\n",
      " ...\n",
      " [ 0.02820305  0.08696805  0.01746436 ...  0.0338297  -0.04200668\n",
      "   0.00789222]\n",
      " [-0.01964607  0.03022924  0.03099425 ... -0.0782057  -0.1084028\n",
      "  -0.02260338]\n",
      " [-0.08511829  0.05696283 -0.08482104 ... -0.05781307  0.05345576\n",
      "   0.00556867]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_text = [doc.page_content for doc in chunked_document]\n",
    "\n",
    "embeddings = embedding_manager.generate_embedding(chunk_text)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aa4966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(chunked_document,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09ed7edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2232\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0694c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e60971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class RAGRetriever:\n",
    "\n",
    "    def __init__(self,vector_store:VectorStore,embedding_manager:EmbeddingManager):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self,query:str,top_k:int = 5,score_threshold:float = 0.25)->List[Dict[str,Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "\n",
    "        query_embeddings = self.embedding_manager.generate_embedding([query])\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=query_embeddings,\n",
    "                n_results=top_k)\n",
    "            \n",
    "            retrieved_docs = []\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "\n",
    "                for i,(doc_id,distance,metadata,document) in enumerate(zip(ids,distances,metadatas,documents)):\n",
    "                    similarity_score = 1-distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "        \n",
    "\n",
    "\n",
    "rag = RAGRetriever(vector_store,embedding_manager)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef4b86f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the growth outlook for India in 2024?\"\n",
    "docs = rag.retrieve(query)\n",
    "\n",
    "if not docs:\n",
    "    print(\"The documents do not contain enough information to answer this question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acab8207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_b2be1551_911',\n",
       "  'content': \"citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. India’s strength has always been its institutions, and, many a time, \\nthe institutional strength has enabled the country to wade through multiple challenges. \\n5.33.\\t The structural reforms undertaken by the Government of India over the course of the \\nlast decade have put the economy firmly on a growth path, thanks to which India is soon set \\nto become the third largest economy in the world, following the US and China. In its April \\n2024 World Economic Outlook, the IMF has raised India's growth forecast for 2024-25 to\\xa06.8 \\nper cent\\xa0from 6.5 per cent on the back of strong domestic demand and a rising working-age\",\n",
       "  'metadata': {'trapped': '',\n",
       "   'creator': 'Adobe InDesign 17.4 (Windows)',\n",
       "   'doc_index': 911,\n",
       "   'author': '',\n",
       "   'creationdate': '2024-07-20T20:21:03+05:30',\n",
       "   'source': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'subject': '',\n",
       "   'page': 222,\n",
       "   'title': '',\n",
       "   'file_type': 'pdf',\n",
       "   'source_file': 'ecsurvey.pdf',\n",
       "   'moddate': '2024-07-22T11:48:47+05:30',\n",
       "   'content_length': 737,\n",
       "   'creationDate': \"D:20240720202103+05'30'\",\n",
       "   'total_pages': 524,\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'keywords': '',\n",
       "   'producer': 'Adobe PDF Library 16.0.7',\n",
       "   'format': 'PDF 1.6',\n",
       "   'modDate': \"D:20240722114847+05'30'\",\n",
       "   'creationdata': '2026-01-12 23:52:00.638573'},\n",
       "  'similarity_score': 0.4310893416404724,\n",
       "  'distance': 0.5689106583595276,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_61736954_911',\n",
       "  'content': \"citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. India’s strength has always been its institutions, and, many a time, \\nthe institutional strength has enabled the country to wade through multiple challenges. \\n5.33.\\t The structural reforms undertaken by the Government of India over the course of the \\nlast decade have put the economy firmly on a growth path, thanks to which India is soon set \\nto become the third largest economy in the world, following the US and China. In its April \\n2024 World Economic Outlook, the IMF has raised India's growth forecast for 2024-25 to\\xa06.8 \\nper cent\\xa0from 6.5 per cent on the back of strong domestic demand and a rising working-age\",\n",
       "  'metadata': {'creationdate': '2024-07-20T20:21:03+05:30',\n",
       "   'moddate': '2024-07-22T11:48:47+05:30',\n",
       "   'creator': 'Adobe InDesign 17.4 (Windows)',\n",
       "   'keywords': '',\n",
       "   'trapped': '',\n",
       "   'producer': 'Adobe PDF Library 16.0.7',\n",
       "   'title': '',\n",
       "   'doc_index': 911,\n",
       "   'author': '',\n",
       "   'total_pages': 524,\n",
       "   'source': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'page': 222,\n",
       "   'creationDate': \"D:20240720202103+05'30'\",\n",
       "   'format': 'PDF 1.6',\n",
       "   'creationdata': '2026-01-13 00:09:11.571998',\n",
       "   'source_file': 'ecsurvey.pdf',\n",
       "   'subject': '',\n",
       "   'content_length': 737,\n",
       "   'modDate': \"D:20240722114847+05'30'\",\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\ecsurvey.pdf'},\n",
       "  'similarity_score': 0.4310893416404724,\n",
       "  'distance': 0.5689106583595276,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_fb835583_911',\n",
       "  'content': \"citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. India’s strength has always been its institutions, and, many a time, \\nthe institutional strength has enabled the country to wade through multiple challenges. \\n5.33.\\t The structural reforms undertaken by the Government of India over the course of the \\nlast decade have put the economy firmly on a growth path, thanks to which India is soon set \\nto become the third largest economy in the world, following the US and China. In its April \\n2024 World Economic Outlook, the IMF has raised India's growth forecast for 2024-25 to\\xa06.8 \\nper cent\\xa0from 6.5 per cent on the back of strong domestic demand and a rising working-age\",\n",
       "  'metadata': {'file_path': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'doc_index': 911,\n",
       "   'modDate': \"D:20240722114847+05'30'\",\n",
       "   'format': 'PDF 1.6',\n",
       "   'creationDate': \"D:20240720202103+05'30'\",\n",
       "   'producer': 'Adobe PDF Library 16.0.7',\n",
       "   'subject': '',\n",
       "   'content_length': 737,\n",
       "   'total_pages': 524,\n",
       "   'source_file': 'ecsurvey.pdf',\n",
       "   'trapped': '',\n",
       "   'creationdata': '2026-01-20 10:52:49.233477',\n",
       "   'moddate': '2024-07-22T11:48:47+05:30',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'creator': 'Adobe InDesign 17.4 (Windows)',\n",
       "   'source': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'creationdate': '2024-07-20T20:21:03+05:30',\n",
       "   'page': 222,\n",
       "   'keywords': '',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.4310893416404724,\n",
       "  'distance': 0.5689106583595276,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_4d0b6277_794',\n",
       "  'content': 'current prices. Fast forward to 2024, and it is estimated to have reached a staggering USD 3.6 \\ntrillion. This represents a remarkable 12-fold increase despite the Indian rupee depreciating by \\naround 3 per cent annually between 1993 and 2024. Moreover, this has been achieved without \\na big rise in the country’s overall indebtedness, indicating an efficient utilisation of capital. \\nIndia’s per capita current dollar GDP has increased from 301.5 in 1993 to 2,484.8 in 2023,1 \\nwhich indicates a substantial improvement in the standard of living. \\n5.2.\\t\\nIndia is a historical and long civilisation. It provided answers to many questions that \\nhumankind faced and still faces. It is a country with a big land mass and a huge population. It',\n",
       "  'metadata': {'total_pages': 524,\n",
       "   'modDate': \"D:20240722114847+05'30'\",\n",
       "   'format': 'PDF 1.6',\n",
       "   'doc_index': 794,\n",
       "   'content_length': 738,\n",
       "   'source': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'creator': 'Adobe InDesign 17.4 (Windows)',\n",
       "   'creationdata': '2026-01-12 23:52:00.638545',\n",
       "   'moddate': '2024-07-22T11:48:47+05:30',\n",
       "   'trapped': '',\n",
       "   'source_file': 'ecsurvey.pdf',\n",
       "   'page': 201,\n",
       "   'producer': 'Adobe PDF Library 16.0.7',\n",
       "   'keywords': '',\n",
       "   'author': '',\n",
       "   'title': '',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'subject': '',\n",
       "   'file_type': 'pdf',\n",
       "   'creationdate': '2024-07-20T20:21:03+05:30',\n",
       "   'creationDate': \"D:20240720202103+05'30'\"},\n",
       "  'similarity_score': 0.42921847105026245,\n",
       "  'distance': 0.5707815289497375,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_60cd9d4f_794',\n",
       "  'content': 'current prices. Fast forward to 2024, and it is estimated to have reached a staggering USD 3.6 \\ntrillion. This represents a remarkable 12-fold increase despite the Indian rupee depreciating by \\naround 3 per cent annually between 1993 and 2024. Moreover, this has been achieved without \\na big rise in the country’s overall indebtedness, indicating an efficient utilisation of capital. \\nIndia’s per capita current dollar GDP has increased from 301.5 in 1993 to 2,484.8 in 2023,1 \\nwhich indicates a substantial improvement in the standard of living. \\n5.2.\\t\\nIndia is a historical and long civilisation. It provided answers to many questions that \\nhumankind faced and still faces. It is a country with a big land mass and a huge population. It',\n",
       "  'metadata': {'author': '',\n",
       "   'creator': 'Adobe InDesign 17.4 (Windows)',\n",
       "   'keywords': '',\n",
       "   'page': 201,\n",
       "   'trapped': '',\n",
       "   'producer': 'Adobe PDF Library 16.0.7',\n",
       "   'content_length': 738,\n",
       "   'title': '',\n",
       "   'modDate': \"D:20240722114847+05'30'\",\n",
       "   'creationdate': '2024-07-20T20:21:03+05:30',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'source': '..\\\\data\\\\pdf\\\\ecsurvey.pdf',\n",
       "   'creationDate': \"D:20240720202103+05'30'\",\n",
       "   'moddate': '2024-07-22T11:48:47+05:30',\n",
       "   'total_pages': 524,\n",
       "   'subject': '',\n",
       "   'format': 'PDF 1.6',\n",
       "   'doc_index': 794,\n",
       "   'source_file': 'ecsurvey.pdf',\n",
       "   'creationdata': '2026-01-20 10:52:49.233435'},\n",
       "  'similarity_score': 0.42921847105026245,\n",
       "  'distance': 0.5707815289497375,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797261a6",
   "metadata": {},
   "source": [
    "## RAG Pipeline Vector DB to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d24c4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "from langchain.messages import HumanMessage,SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5500a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self,model_name:str=\"meta-llama/llama-4-maverick-17b-128e-instruct\"):\n",
    "        self.model_name = model_name\n",
    "        self.api_keys = GROQ_API_KEY\n",
    "\n",
    "        if not self.api_keys:\n",
    "            raise ValueError(\"API Key Not Found\")\n",
    "        \n",
    "        self.llm=ChatGroq(\n",
    "            model = self.model_name,\n",
    "            temperature=0.3,\n",
    "            max_tokens=2048,\n",
    "        )\n",
    "        \n",
    "        # self.prompt = ChatPromptTemplate.from_messages([\n",
    "        #     (\"system\", \"You are a helpful AI assistant. Answer ONLY using the provided context. If the context does not contain the answer, say so clearly.\"),\n",
    "        #     (\"human\", \"Context:\\n{context}\\n\\nQuestion:\\n{question}\")\n",
    "        # ])\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "   \n",
    "             SystemMessage(\n",
    "                    content=\"You are a helpful AI assistant. Answer ONLY using the provided context.\"\n",
    "            ),\n",
    "    \n",
    "\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                    \"Context:\\n{context}\\n\\nQuestion:\\n{question}\"\n",
    "             )\n",
    "        ])\n",
    "\n",
    "    def invoke(self,query:str)->str:\n",
    "        try:\n",
    "            response = self.llm.invoke(query)\n",
    "            return str(response.content)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "        \n",
    "        \n",
    "    def generate_response(self,query:str,context:str,max_length:int = 1000)->str:\n",
    "        try:\n",
    "            chain = self.prompt | self.llm\n",
    "            \n",
    "            response = chain.invoke({\n",
    "                \"question\": query,\n",
    "                \"context\": context\n",
    "            })\n",
    "\n",
    "\n",
    "            print(\"Generating LLM Response from query and context\")\n",
    "            return str(response.content)\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cff355f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq LLM initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    groq_llm = LLM()\n",
    "    print(\"Groq LLM initialized successfully!\")\n",
    "except ValueError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    groq_llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "852d8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_retrive(query,rag,llm,top_k=2):\n",
    "    result = rag.retrieve(query,top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in result]) if result else \"\"\n",
    "    \n",
    "    if not context:\n",
    "        return \"No Answer\"\n",
    "    \n",
    "    response = llm.generate_response(\n",
    "        query=query,\n",
    "        context=context\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "964ce170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 2 documents (after filtering)\n",
      "Generating LLM Response from query and context\n",
      "According to the text, the IMF has raised India's growth forecast for 2024-25 to 6.8 per cent from 6.5 per cent. This indicates a positive growth outlook for India in 2024, driven by strong domestic demand and a rising working-age population.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the growth outlook for India in 2024?\"\n",
    "ans = rag_retrive(query,rag,llm=groq_llm)\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7951d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, rag, llm):\n",
    "        self.retriever = rag\n",
    "        self.llm = llm\n",
    "        self.history = [] \n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "    \n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        \n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.generate_response(context=context, query=question)\n",
    "            answer = response\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5028be0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 documents (after filtering)\n",
      "Generating LLM Response from query and context\n",
      "{'question': 'What is the growth outlook for India in 2024?', 'answer': \"The IMF has raised India's growth forecast for 2024-25 to 6.8 per cent from 6.5 per cent on the back of strong domestic demand and a rising working-age population.\\n\\nCitations:\\n[1] ecsurvey.pdf (page 222)\\n[2] ecsurvey.pdf (page 222)\\n[3] ecsurvey.pdf (page 222)\\n[4] ecsurvey.pdf (page 201)\\n[5] ecsurvey.pdf (page 201)\", 'sources': [{'source': 'ecsurvey.pdf', 'page': 222, 'score': 0.4310893416404724, 'preview': 'citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. ...'}, {'source': 'ecsurvey.pdf', 'page': 222, 'score': 0.4310893416404724, 'preview': 'citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. ...'}, {'source': 'ecsurvey.pdf', 'page': 222, 'score': 0.4310893416404724, 'preview': 'citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. ...'}, {'source': 'ecsurvey.pdf', 'page': 201, 'score': 0.42921847105026245, 'preview': 'current prices. Fast forward to 2024, and it is estimated to have reached a staggering USD 3.6 \\ntrillion. This represent...'}, {'source': 'ecsurvey.pdf', 'page': 201, 'score': 0.42921847105026245, 'preview': 'current prices. Fast forward to 2024, and it is estimated to have reached a staggering USD 3.6 \\ntrillion. This represent...'}], 'summary': None, 'history': [{'question': 'What is the growth outlook for India in 2024?', 'answer': \"The IMF has raised India's growth forecast for 2024-25 to 6.8 per cent from 6.5 per cent on the back of strong domestic demand and a rising working-age population.\", 'sources': [{'source': 'ecsurvey.pdf', 'page': 222, 'score': 0.4310893416404724, 'preview': 'citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. ...'}, {'source': 'ecsurvey.pdf', 'page': 222, 'score': 0.4310893416404724, 'preview': 'citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. ...'}, {'source': 'ecsurvey.pdf', 'page': 222, 'score': 0.4310893416404724, 'preview': 'citizens while ensuring that the growth momentum continued to be sustained through a wide \\nrange of structural reforms. ...'}, {'source': 'ecsurvey.pdf', 'page': 201, 'score': 0.42921847105026245, 'preview': 'current prices. Fast forward to 2024, and it is estimated to have reached a staggering USD 3.6 \\ntrillion. This represent...'}, {'source': 'ecsurvey.pdf', 'page': 201, 'score': 0.42921847105026245, 'preview': 'current prices. Fast forward to 2024, and it is estimated to have reached a staggering USD 3.6 \\ntrillion. This represent...'}], 'summary': None}]}\n"
     ]
    }
   ],
   "source": [
    "adv_RAG = AdvancedRAGPipeline(rag=rag,llm=groq_llm)\n",
    "ans = adv_RAG.query(query)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b6b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multi-source-RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
